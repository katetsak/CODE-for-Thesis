{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "added_stocks_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS 1\\ADDED_STOCKS.xlsx\"\n",
    "excel_data = pd.ExcelFile(added_stocks_path)\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for sheet_name in excel_data.sheet_names:\n",
    "    df = pd.read_excel(added_stocks_path, sheet_name=sheet_name)\n",
    "    \n",
    "    df['Excess_Return'] = df['stock_return'] - df['market_return']\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    df['year'] = df['date'].dt.year\n",
    "  \n",
    "    yearly_excess_return = df.groupby('year')['Excess_Return'].sum().reset_index()\n",
    "    \n",
    "    yearly_excess_return['Company'] = sheet_name\n",
    "    \n",
    "    results_list.append(yearly_excess_return)\n",
    "\n",
    "excess_return_results = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "results_path = r\"C:\\UU\\THESIS\\AMX\\REGRESSION ANALYSIS\\use_2005+\\ADDED_Yearly_Excess_Return_Results.xlsx\"\n",
    "excess_return_results.to_excel(results_path, index=False)\n",
    "\n",
    "print(excess_return_results.head())\n",
    "\n",
    "company_dfs = {}\n",
    "\n",
    "for company in excess_return_results['Company'].unique():\n",
    "   \n",
    "    company_data = excess_return_results[excess_return_results['Company'] == company]\n",
    "    \n",
    "    company_data = company_data.sort_values(by='year')\n",
    "\n",
    "    company_data['event'] = range(0, min(6, len(company_data)))\n",
    "    \n",
    "    company_data = company_data[['event', 'year', 'Excess_Return']]\n",
    "    \n",
    "    company_dfs[company] = company_data\n",
    "\n",
    "output_path = r\"C:\\UU\\THESIS\\AMX\\REGRESSION ANALYSIS\\use_2005+\\ADDED_Transformed_Excess_Return_Results.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for company, df in company_dfs.items():\n",
    "        df.to_excel(writer, sheet_name=company, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats.mstats import winsorize\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "\n",
    "added_excess_returns_path = r\"C:\\UU\\THESIS\\AMX\\REGRESSION ANALYSIS\\use_2005+\\ADDED_Transformed_Excess_Return_Results_IO_NO.xlsx\"\n",
    "added_proxies_path = r\"C:\\UU\\THESIS\\AMX\\REGRESSION ANALYSIS\\use_2005+\\ADDED_PROXIES -2005+ IO_NO.xlsx\"\n",
    "deleted_excess_returns_path = r\"C:\\UU\\THESIS\\AMX\\REGRESSION ANALYSIS\\use_2005+\\DELETED_Transformed_Excess_Return_Results_2005+_IO_NO.xlsx\"\n",
    "deleted_proxies_path = r\"C:\\UU\\THESIS\\AMX\\REGRESSION ANALYSIS\\use_2005+\\DELETED_PROXIES IO_NO.xlsx\"\n",
    "\n",
    "added_proxies_sheets = pd.read_excel(added_proxies_path, sheet_name=None)\n",
    "deleted_proxies_sheets = pd.read_excel(deleted_proxies_path, sheet_name=None)\n",
    "added_excess_return_results_sheets = pd.read_excel(added_excess_returns_path, sheet_name=None)\n",
    "deleted_excess_return_results_sheets = pd.read_excel(deleted_excess_returns_path, sheet_name=None)\n",
    "\n",
    "combined_added_proxies_df = pd.concat(added_proxies_sheets.values(), ignore_index=True)\n",
    "combined_deleted_proxies_df = pd.concat(deleted_proxies_sheets.values(), ignore_index=True)\n",
    "combined_added_excess_return_results_df = pd.concat(added_excess_return_results_sheets.values(), ignore_index=True)\n",
    "combined_deleted_excess_return_results_df = pd.concat(deleted_excess_return_results_sheets.values(), ignore_index=True)\n",
    "\n",
    "combined_added_proxies_df['company'] = combined_added_proxies_df.index // (len(combined_added_proxies_df) // len(added_proxies_sheets))\n",
    "combined_deleted_proxies_df['company'] = combined_deleted_proxies_df.index // (len(combined_deleted_proxies_df) // len(deleted_proxies_sheets))\n",
    "combined_added_excess_return_results_df['company'] = combined_added_excess_return_results_df.index // (len(combined_added_excess_return_results_df) // len(added_excess_return_results_sheets))\n",
    "combined_deleted_excess_return_results_df['company'] = combined_deleted_excess_return_results_df.index // (len(combined_deleted_excess_return_results_df) // len(deleted_excess_return_results_sheets))\n",
    "\n",
    "#add a dummy variable: 0 for added, 1 for deleted\n",
    "combined_added_proxies_df['deleted_stock'] = 0\n",
    "combined_deleted_proxies_df['deleted_stock'] = 1\n",
    "\n",
    "#merge the combined dataframes on the common 'event' and 'company' columns\n",
    "combined_added_merged_df = pd.merge(combined_added_proxies_df, combined_added_excess_return_results_df, on=['event', 'company'])\n",
    "combined_deleted_merged_df = pd.merge(combined_deleted_proxies_df, combined_deleted_excess_return_results_df, on=['event', 'company'])\n",
    "\n",
    "combined_merged_df = pd.concat([combined_added_merged_df, combined_deleted_merged_df], ignore_index=True)\n",
    "\n",
    "event_0_df = combined_merged_df[combined_merged_df['event'] == 0].set_index('company')\n",
    "event_5_df = combined_merged_df[combined_merged_df['event'] == 5].set_index('company')\n",
    "\n",
    "#calculate the changes\n",
    "diff_df = event_5_df.copy()\n",
    "diff_df['DIO_NO'] = event_5_df['IO_NO'] - event_0_df['IO_NO']\n",
    "diff_df['DIlliquidity'] = event_5_df['illiquidity'] - event_0_df['illiquidity']\n",
    "diff_df['DROA'] = event_5_df['roa_adjusted'] - event_0_df['roa_adjusted']\n",
    "diff_df['DDispersion'] = (event_5_df['dispersion'] - event_0_df['dispersion']) / event_0_df['dispersion']\n",
    "diff_df['Excess_Return'] = event_5_df['Excess_Return']  # Ensure this column is available\n",
    "diff_df['deleted_stock'] = event_5_df['deleted_stock']\n",
    "\n",
    "diff_df['company'] = event_5_df.index\n",
    "\n",
    "#winsorize the variables at 5%\n",
    "for column in [ 'DDispersion',  'DIlliquidity','DIO_NO', 'DROA', 'Excess_Return']:\n",
    "    diff_df[column] = winsorize(diff_df[column], limits=[0.05, 0.05])\n",
    "\n",
    "diff_df = diff_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "diff_df = pd.get_dummies(diff_df, columns=['year'], drop_first=True)\n",
    "\n",
    "diff_df = diff_df.replace([float('inf'), float('-inf')], pd.NA).dropna(subset=['DDispersion', 'DIO_NO','DIlliquidity', 'DROA', 'Excess_Return', 'deleted_stock'])\n",
    "\n",
    "#define the dependent and independent variables for the regression\n",
    "X = diff_df[['DDispersion', 'DIO_NO','DIlliquidity', 'DROA','deleted_stock'] + [col for col in diff_df.columns if col.startswith('year_')]]\n",
    "y = diff_df['Excess_Return']\n",
    "\n",
    "X = X[X.index.isin(y.index)].astype(float)\n",
    "y = y[y.index.isin(X.index)].astype(float)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "#perform the OLS regression and cluster standard errors by firm\n",
    "model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': diff_df['company']})\n",
    "\n",
    "print(\"Regression Results for Combined Stocks with Dummy Variable\")\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
