{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "data = pd.read_excel(r\"C:\\UU\\THESIS\\AMX\\monthly prices 2002-2007\\ADDED\\hypothesis2\\added2.xlsx\", sheet_name=None)\n",
    "\n",
    "combined_data = pd.concat(data.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "for sheet_name, df in data.items():\n",
    "    if df.empty:\n",
    "        continue\n",
    "    \n",
    "#extracting the first digit of the SIC code to classify companies into industry sectors\n",
    "combined_data['sic_code_first_digit'] = combined_data['sic_code'].astype(str).str[0]\n",
    "\n",
    "#calculating performance measures\n",
    "combined_data['profit_margin'] = (combined_data['net_income'] / combined_data['sales']) *100\n",
    "combined_data['operating_margin'] = (combined_data['operating_income'] / combined_data['sales'])*100\n",
    "combined_data['roa'] = (combined_data['net_income'] / combined_data['total_assets']) *100\n",
    "combined_data['oibd_to_assets'] = (combined_data['oibd'] / combined_data['total_assets']) *100\n",
    "combined_data['market_to_book'] = (combined_data['mv'] / (combined_data['book_value'] * combined_data['com_shares_outstanding'])) *100\n",
    "\n",
    "#define the performance measures\n",
    "measures = ['profit_margin', 'operating_margin', 'roa', 'oibd_to_assets', 'market_to_book']\n",
    "\n",
    "combined_data['date'] = pd.to_datetime(combined_data['date'])\n",
    "\n",
    "#function to calculate industry averages and adjust performance measures\n",
    "def adjust_performance_measures(data, measures):\n",
    "    adjusted_data = data.copy()\n",
    "    for measure in measures:\n",
    "        #calculate industry averages by year and first digit of SIC code\n",
    "        industry_averages = data.groupby(['date', 'sic_code_first_digit'])[measure].transform('mean')\n",
    "        #print(industry_averages)\n",
    "\n",
    "        #adjust the performance measures\n",
    "        adjusted_data[f'{measure}_adjusted'] = data[measure] - industry_averages\n",
    "\n",
    "    return adjusted_data\n",
    "\n",
    "#adjust the performance measures\n",
    "adjusted_data = adjust_performance_measures(combined_data, measures)\n",
    "\n",
    "#select necessary columns for analysis\n",
    "adjusted_columns = ['date', 'sic_code', 'sic_code_first_digit'] + [f'{measure}_adjusted' for measure in measures]\n",
    "adjusted_data = adjusted_data[adjusted_columns]\n",
    "\n",
    "output_file = r\"C:\\UU\\THESIS\\AMX\\monthly prices 2002-2007\\ADDED\\hypothesis2\\adj_data.xlsx\"\n",
    "adjusted_data.to_excel(output_file, sheet_name='adj_data', index=True)\n",
    "\n",
    "adjusted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "data = pd.read_excel(r\"C:\\UU\\THESIS\\AMX\\monthly prices 2002-2007\\DELETED\\hypothesis2\\deleted2.xlsx\", sheet_name=None)\n",
    "\n",
    "combined_data = pd.concat(data.values(), ignore_index=True)\n",
    "\n",
    "for sheet_name, df in data.items():\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "\n",
    "#extracting the first digit of the SIC code to classify companies into industry sectors\n",
    "combined_data['sic_code_first_digit'] = combined_data['sic_code'].astype(str).str[0]\n",
    "\n",
    "#calculating performance measures\n",
    "combined_data['profit_margin'] = (combined_data['net_income'] / combined_data['sales']) *100\n",
    "combined_data['operating_margin'] = (combined_data['operating_income'] / combined_data['sales'])*100\n",
    "combined_data['roa'] = (combined_data['net_income'] / combined_data['total_assets']) *100\n",
    "combined_data['oibd_to_assets'] = (combined_data['oibd'] / combined_data['total_assets']) *100\n",
    "combined_data['market_to_book'] = (combined_data['mv'] / (combined_data['book_value'] * combined_data['com_shares_outstanding'])) *100\n",
    "\n",
    "#define the performance measures\n",
    "measures = ['profit_margin', 'operating_margin', 'roa', 'oibd_to_assets', 'market_to_book']\n",
    "\n",
    "combined_data['date'] = pd.to_datetime(combined_data['date'])\n",
    "\n",
    "#function to calculate industry averages and adjust performance measures\n",
    "def adjust_performance_measures(data, measures):\n",
    "    adjusted_data = data.copy()\n",
    "    for measure in measures:\n",
    "        for date, group in data.groupby('date'):\n",
    "            for sic_code, subgroup in group.groupby('sic_code_first_digit'):\n",
    "                if len(subgroup) > 1:\n",
    "                    industry_average = subgroup[measure].mean()\n",
    "                    adjusted_data.loc[subgroup.index, f'{measure}_adjusted'] = subgroup[measure] - industry_average\n",
    "                else:\n",
    "                    adjusted_data.loc[subgroup.index, f'{measure}_adjusted'] = subgroup[measure]\n",
    "    return adjusted_data\n",
    "\n",
    "#adjust the performance measures\n",
    "adjusted_data = adjust_performance_measures(combined_data, measures)\n",
    "\n",
    "#select necessary columns for analysis\n",
    "adjusted_columns = ['date', 'sic_code', 'sic_code_first_digit'] + [f'{measure}_adjusted' for measure in measures]\n",
    "adjusted_data = adjusted_data[adjusted_columns]\n",
    "\n",
    "output_file = r\"C:\\UU\\THESIS\\AMX\\monthly prices 2002-2007\\DELETED\\hypothesis2\\adj_data.xlsx\"\n",
    "adjusted_data.to_excel(output_file, sheet_name='adj_data', index=True)\n",
    "\n",
    "\n",
    "adjusted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu, wilcoxon, binomtest, ttest_rel\n",
    "import numpy as np\n",
    "\n",
    "file_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS 2\\DELETED\\deleted - Copy.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "data = pd.concat([pd.read_excel(xls, sheet_name=sheet) for sheet in xls.sheet_names])\n",
    "\n",
    "#define the periods for t-5, t, and t+5\n",
    "periods_deleted = {\n",
    "    't-5': 0,\n",
    "    't': 5,\n",
    "    't+5': 10\n",
    "}\n",
    "\n",
    "df_t_minus_5 = data[data['years'] == periods_deleted['t-5']]\n",
    "df_t = data[data['years'] == periods_deleted['t']]\n",
    "df_t_plus_5 = data[data['years'] == periods_deleted['t+5']]\n",
    "\n",
    "df_t_minus_5 = df_t_minus_5.sort_values(by='years').reset_index(drop=True)\n",
    "df_t = df_t.sort_values(by='years').reset_index(drop=True)\n",
    "df_t_plus_5 = df_t_plus_5.sort_values(by='years').reset_index(drop=True)\n",
    "\n",
    "#define the columns to test\n",
    "columns_to_test = [ 'profit_margin_adjusted',\n",
    "    'roa_adjusted', 'oibd_to_assets_adjusted', 'market_to_book_adjusted']\n",
    "\n",
    "results = {\n",
    "    'mann_whitney': {'Measure': [], 'Period': [], 'Statistic': [], 'p-value': []},\n",
    "    'wilcoxon': {'Measure': [], 'Period': [], 'Statistic': [], 't-value': [], 'p-value': []},\n",
    "    'sign_test': {'Measure': [], 'Period': [], 'Statistic': [], 'p-value': []},\n",
    "    'paired_ttest': {'Measure': [], 'Period': [], 'Statistic': [], 'p-value': []}\n",
    "}\n",
    "\n",
    "def perform_wilcoxon_test(df1, df2, column):\n",
    "    data1 = df1[column].dropna().values\n",
    "    data2 = df2[column].dropna().values\n",
    "    if len(data1) == 0 or len(data2) == 0:\n",
    "        return (None, None, None)\n",
    "    \n",
    "    stat, p_value = wilcoxon(data1, data2)\n",
    "    \n",
    "    #calculate the t-value from the Wilcoxon statistic\n",
    "    n = len(data1)\n",
    "    mu_w = n * (n + 1) / 4\n",
    "    sigma_w = np.sqrt(n * (n + 1) * (2 * n + 1) / 24)\n",
    "    t_value = (stat - mu_w) / sigma_w\n",
    "    \n",
    "    return stat, t_value, p_value\n",
    "\n",
    "#function to perform the Sign Test\n",
    "def perform_sign_test(df1, df2, column):\n",
    "    data1 = df1[column].dropna().values\n",
    "    data2 = df2[column].dropna().values\n",
    "    min_length = min(len(data1), len(data2))\n",
    "    data1 = data1[:min_length]\n",
    "    data2 = data2[:min_length]\n",
    "    differences = data1 - data2\n",
    "    n_positive = sum(differences > 0)\n",
    "    n_negative = sum(differences < 0)\n",
    "    n_total = n_positive + n_negative\n",
    "    if n_total == 0:\n",
    "        return (None, None)\n",
    "    p_value = binomtest(n_positive, n_total, 0.5, alternative='two-sided').pvalue\n",
    "    return (n_positive - n_negative, p_value)\n",
    "\n",
    "for column in columns_to_test:\n",
    "    # Mann-Whitney U Test\n",
    "    if not df_t_minus_5[column].dropna().empty and not df_t[column].dropna().empty:\n",
    "        stat, p_value = mannwhitneyu(df_t_minus_5[column], df_t[column], alternative='two-sided')\n",
    "        results['mann_whitney']['Measure'].append(column)\n",
    "        results['mann_whitney']['Period'].append('t-5 vs t')\n",
    "        results['mann_whitney']['Statistic'].append(stat)\n",
    "        results['mann_whitney']['p-value'].append(p_value)\n",
    "        \n",
    "    if not df_t[column].dropna().empty and not df_t_plus_5[column].dropna().empty:\n",
    "        stat, p_value = mannwhitneyu(df_t[column], df_t_plus_5[column], alternative='two-sided')\n",
    "        results['mann_whitney']['Measure'].append(column)\n",
    "        results['mann_whitney']['Period'].append('t vs t+5')\n",
    "        results['mann_whitney']['Statistic'].append(stat)\n",
    "        results['mann_whitney']['p-value'].append(p_value)\n",
    "\n",
    "    #Wilcoxon Signed Rank Test\n",
    "    stat, t_value, p_value = perform_wilcoxon_test(df_t_minus_5, df_t, column)\n",
    "    results['wilcoxon']['Measure'].append(column)\n",
    "    results['wilcoxon']['Period'].append('t-5 vs t')\n",
    "    results['wilcoxon']['Statistic'].append(stat)\n",
    "    results['wilcoxon']['t-value'].append(t_value)\n",
    "    results['wilcoxon']['p-value'].append(p_value)\n",
    "    \n",
    "    stat, t_value, p_value = perform_wilcoxon_test(df_t, df_t_plus_5, column)\n",
    "    results['wilcoxon']['Measure'].append(column)\n",
    "    results['wilcoxon']['Period'].append('t vs t+5')\n",
    "    results['wilcoxon']['Statistic'].append(stat)\n",
    "    results['wilcoxon']['t-value'].append(t_value)\n",
    "    results['wilcoxon']['p-value'].append(p_value)\n",
    "\n",
    "\n",
    "    #sign Test\n",
    "    stat, p_value = perform_sign_test(df_t_minus_5, df_t, column)\n",
    "    results['sign_test']['Measure'].append(column)\n",
    "    results['sign_test']['Period'].append('t-5 vs t')\n",
    "    results['sign_test']['Statistic'].append(stat)\n",
    "    results['sign_test']['p-value'].append(p_value)\n",
    "    \n",
    "    stat, p_value = perform_sign_test(df_t, df_t_plus_5, column)\n",
    "    results['sign_test']['Measure'].append(column)\n",
    "    results['sign_test']['Period'].append('t vs t+5')\n",
    "    results['sign_test']['Statistic'].append(stat)\n",
    "    results['sign_test']['p-value'].append(p_value)\n",
    "    \n",
    "    #paired T-Test\n",
    "    data_t_minus_5 = df_t_minus_5[column].dropna().values\n",
    "    data_t = df_t[column].dropna().values\n",
    "    data_t_plus_5 = df_t_plus_5[column].dropna().values\n",
    "    min_length_t_minus_5_t = min(len(data_t_minus_5), len(data_t))\n",
    "    min_length_t_t_plus_5 = min(len(data_t), len(data_t_plus_5))\n",
    "    data_t_minus_5 = data_t_minus_5[:min_length_t_minus_5_t]\n",
    "    data_t = data_t[:min_length_t_minus_5_t]\n",
    "    data_t_plus_5 = data_t_plus_5[:min_length_t_t_plus_5]\n",
    "    if len(data_t_minus_5) > 1 and len(data_t) > 1:\n",
    "        stat, p_value = ttest_rel(data_t_minus_5, data_t)\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t-5 vs t')\n",
    "        results['paired_ttest']['Statistic'].append(stat)\n",
    "        results['paired_ttest']['p-value'].append(p_value)\n",
    "    else:\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t-5 vs t')\n",
    "        results['paired_ttest']['Statistic'].append(None)\n",
    "        results['paired_ttest']['p-value'].append(None)\n",
    "    if len(data_t) > 1 and len(data_t_plus_5) > 1:\n",
    "        stat, p_value = ttest_rel(data_t, data_t_plus_5)\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t vs t+5')\n",
    "        results['paired_ttest']['Statistic'].append(stat)\n",
    "        results['paired_ttest']['p-value'].append(p_value)\n",
    "    else:\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t vs t+5')\n",
    "        results['paired_ttest']['Statistic'].append(None)\n",
    "        results['paired_ttest']['p-value'].append(None)\n",
    "\n",
    "#convert results to DataFrames\n",
    "results_mann_whitney_df = pd.DataFrame(results['mann_whitney'])\n",
    "results_wilcoxon_df = pd.DataFrame(results['wilcoxon'])\n",
    "results_sign_test_df = pd.DataFrame(results['sign_test'])\n",
    "results_paired_ttest_df = pd.DataFrame(results['paired_ttest'])\n",
    "\n",
    "print(results_mann_whitney_df)\n",
    "\n",
    "print(results_wilcoxon_df)\n",
    "\n",
    "print(results_sign_test_df)\n",
    "\n",
    "print(results_paired_ttest_df)\n",
    "\n",
    "output_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS 2\\DELETED\\final\\deleted222_significance_test_results_updated.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    results_mann_whitney_df.to_excel(writer, sheet_name='Mann-Whitney')\n",
    "    results_wilcoxon_df.to_excel(writer, sheet_name='Wilcoxon')\n",
    "    results_sign_test_df.to_excel(writer, sheet_name='Sign Test')\n",
    "    results_paired_ttest_df.to_excel(writer, sheet_name='Paired T-Test')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS 2\\ADDED\\ADDED - Copy.xlsx\"\n",
    "\n",
    "sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "aggregated_results = pd.DataFrame(columns=['years', 'profit_margin_adjusted', 'operating_margin_adjusted',\n",
    "    'roa_adjusted', 'oibd_to_assets_adjusted', 'market_to_book_adjusted'])\n",
    "\n",
    "for sheet_name, df in sheets.items():\n",
    "    if df.empty:\n",
    "        print(f\"Sheet {sheet_name} is empty, skipping.\")\n",
    "        continue  # Skip empty sheets\n",
    "    if 'years' not in df.columns:\n",
    "        continue  # Skip sheets that do not have the required columns\n",
    "    \n",
    "    \n",
    "    df['profit_margin_adjusted'] = pd.to_numeric(df['profit_margin_adjusted'], errors='coerce')\n",
    "    df['operating_margin_adjusted'] = pd.to_numeric(df['operating_margin_adjusted'], errors='coerce')\n",
    "    df['roa_adjusted'] = pd.to_numeric(df['roa_adjusted'], errors='coerce')\n",
    "    df['oibd_to_assets_adjusted'] = pd.to_numeric(df['oibd_to_assets_adjusted'], errors='coerce')\n",
    "    df['market_to_book_adjusted'] = pd.to_numeric(df['market_to_book_adjusted'], errors='coerce')\n",
    "\n",
    "    #group by event year and calculate the mean for coverage and dispersion\n",
    "    mean_proxies = df.groupby('years')[['profit_margin_adjusted', 'operating_margin_adjusted', 'roa_adjusted', 'oibd_to_assets_adjusted', 'market_to_book_adjusted']].mean()\n",
    "\n",
    "    mean_proxies.reset_index(inplace=True)\n",
    "    aggregated_results = pd.concat([aggregated_results, mean_proxies], ignore_index=True)\n",
    "\n",
    "#group by event year again to get the overall mean across all companies\n",
    "final_mean_proxies = aggregated_results.groupby('years').mean()\n",
    "\n",
    "output_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS 2\\ADDED\\ADDED - Copy222_average_proxies_by_event_year.xlsx\"\n",
    "final_mean_proxies.to_excel(output_path)\n",
    "\n",
    "print(\"Average proxies by event year saved to:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
