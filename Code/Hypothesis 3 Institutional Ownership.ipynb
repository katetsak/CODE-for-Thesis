{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_institutional_ownership_proxies(df):\n",
    "    \n",
    "    df = df.dropna(subset=['holders', 'shares_held', 'out_shares'])\n",
    "    df['IO_NO'] = df['holders']\n",
    "    df['IO_RATIO'] = df['shares_held'] / df['out_shares']\n",
    "    \n",
    "    return df[['date', 'IO_NO', 'IO_RATIO']]\n",
    "\n",
    "def process_excel_file(file_path):\n",
    "   \n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    results = {}\n",
    "    \n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name)\n",
    "        if df.empty:\n",
    "            print(f\"Sheet {sheet_name} is empty, skipping.\")\n",
    "            continue  \n",
    "        df.columns = df.columns.str.strip()  \n",
    "        if 'date' not in df.columns:\n",
    "            print(f\"Sheet {sheet_name} does not contain 'date' column, skipping.\")\n",
    "            continue  \n",
    "        \n",
    "        print(f\"Processing sheet {sheet_name}\")\n",
    "        print(df.head())  \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            print(f\"Date column before parsing for {sheet_name}:\\n{df['date'].head()}\")\n",
    "            \n",
    "            df['date'] = pd.to_datetime(df['date'], format='%m/%y', errors='coerce')\n",
    "            \n",
    "            print(f\"Date column after parsing for {sheet_name}:\\n{df['date'].head()}\")\n",
    "            \n",
    "            df.dropna(subset=['date'], inplace=True)\n",
    "            \n",
    "            print(f\"After date parsing and dropping NA, data for {sheet_name}:\\n{df.head()}\")\n",
    "            results[sheet_name] = calculate_institutional_ownership_proxies(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sheet {sheet_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_to_excel(results, output_path):\n",
    "    \n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        for company, data in results.items():\n",
    "            data.to_excel(writer, sheet_name=company)\n",
    "\n",
    "file_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED_OWNERSHIP.xlsx\"\n",
    "output_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED2_institutional_ownership_proxies.xlsx\"\n",
    "\n",
    "results = process_excel_file(file_path)\n",
    "save_to_excel(results, output_path)\n",
    "\n",
    "print(f\"Calculated institutional ownership proxies saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED2_institutional_ownership_proxies.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "def transform_to_yearly(data):\n",
    "    data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "    data = data.set_index('date').resample('Y').mean()\n",
    "    data['year'] = data.index.year\n",
    "    return data.reset_index(drop=True)\n",
    "\n",
    "yearly_data = {sheet_name: transform_to_yearly(sheet_data) for sheet_name, sheet_data in df.items()}\n",
    "\n",
    "output_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED2_yearly_institutional_ownership_proxies.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    for sheet_name, data in yearly_data.items():\n",
    "        data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED2_yearly_institutional_ownership_proxies.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "\n",
    "def calculate_yearly_means(data):\n",
    "    data['event'] = data['event'].astype(int)\n",
    "    yearly_means = data.groupby('event').mean()\n",
    "    return yearly_means\n",
    "\n",
    "aggregated_data = pd.concat([calculate_yearly_means(sheet_data) for sheet_name, sheet_data in df.items()])\n",
    "\n",
    "#calculate the overall yearly mean for each proxy across all companies\n",
    "overall_yearly_means = aggregated_data.groupby('event').mean()\n",
    "\n",
    "output_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED2_overall_yearly_means.xlsx\"\n",
    "overall_yearly_means.to_excel(output_path)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu, wilcoxon, binomtest, ttest_rel\n",
    "import numpy as np\n",
    "\n",
    "file_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED_yearly_institutional_ownership_proxies2.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "data = pd.concat([pd.read_excel(xls, sheet_name=sheet) for sheet in xls.sheet_names])\n",
    "\n",
    "periods_deleted = {\n",
    "    't-5': -5,\n",
    "    't': 0,\n",
    "    't+5': 5\n",
    "}\n",
    "\n",
    "\n",
    "df_t_minus_5 = data[data['event'] == periods_deleted['t-5']]\n",
    "df_t = data[data['event'] == periods_deleted['t']]\n",
    "df_t_plus_5 = data[data['event'] == periods_deleted['t+5']]\n",
    "\n",
    "df_t_minus_5 = df_t_minus_5.sort_values(by='event').reset_index(drop=True)\n",
    "df_t = df_t.sort_values(by='event').reset_index(drop=True)\n",
    "df_t_plus_5 = df_t_plus_5.sort_values(by='event').reset_index(drop=True)\n",
    "\n",
    "columns_to_test = [ 'IO_NO']\n",
    "\n",
    "results = {\n",
    "    'mann_whitney': {'Measure': [], 'Period': [], 'Statistic': [], 'p-value': []},\n",
    "    'wilcoxon': {'Measure': [], 'Period': [], 'Statistic': [], 't-value': [], 'p-value': []},\n",
    "    'sign_test': {'Measure': [], 'Period': [], 'Statistic': [], 'p-value': []},\n",
    "    'paired_ttest': {'Measure': [], 'Period': [], 'Statistic': [], 'p-value': []}\n",
    "}\n",
    "\n",
    "def perform_wilcoxon_test(df1, df2, column):\n",
    "    data1 = df1[column].dropna().values\n",
    "    data2 = df2[column].dropna().values\n",
    "    if len(data1) == 0 or len(data2) == 0:\n",
    "        return (None, None, None)\n",
    "    \n",
    "    stat, p_value = wilcoxon(data1, data2)\n",
    "    \n",
    "    #calculate the t-value from the Wilcoxon statistic\n",
    "    n = len(data2)\n",
    "    mu_w = n * (n + 1) / 4\n",
    "    sigma_w = np.sqrt(n * (n + 1) * (2 * n + 1) / 24)\n",
    "    t_value = (stat - mu_w) / sigma_w\n",
    "    \n",
    "    return stat, t_value, p_value\n",
    "\n",
    "\n",
    "def perform_sign_test(df1, df2, column):\n",
    "    data1 = df1[column].dropna().values\n",
    "    data2 = df2[column].dropna().values\n",
    "    min_length = min(len(data1), len(data2))\n",
    "    data1 = data1[:min_length]\n",
    "    data2 = data2[:min_length]\n",
    "    differences = data1 - data2\n",
    "    n_positive = sum(differences > 0)\n",
    "    n_negative = sum(differences < 0)\n",
    "    n_total = n_positive + n_negative\n",
    "    if n_total == 0:\n",
    "        return (None, None)\n",
    "    p_value = binomtest(n_positive, n_total, 0.5, alternative='two-sided').pvalue\n",
    "    return (n_positive - n_negative, p_value)\n",
    "\n",
    "for column in columns_to_test:\n",
    "    #mann-Whitney U Test\n",
    "    if not df_t_minus_5[column].dropna().empty and not df_t[column].dropna().empty:\n",
    "        stat, p_value = mannwhitneyu(df_t_minus_5[column], df_t[column], alternative='two-sided')\n",
    "        results['mann_whitney']['Measure'].append(column)\n",
    "        results['mann_whitney']['Period'].append('t-5 vs t')\n",
    "        results['mann_whitney']['Statistic'].append(stat)\n",
    "        results['mann_whitney']['p-value'].append(p_value)\n",
    "        \n",
    "    if not df_t[column].dropna().empty and not df_t_plus_5[column].dropna().empty:\n",
    "        stat, p_value = mannwhitneyu(df_t[column], df_t_plus_5[column], alternative='two-sided')\n",
    "        results['mann_whitney']['Measure'].append(column)\n",
    "        results['mann_whitney']['Period'].append('t vs t+5')\n",
    "        results['mann_whitney']['Statistic'].append(stat)\n",
    "        results['mann_whitney']['p-value'].append(p_value)\n",
    "\n",
    "    #Wilcoxon Signed Rank Test\n",
    "    stat, t_value, p_value = perform_wilcoxon_test(df_t_minus_5, df_t, column)\n",
    "    results['wilcoxon']['Measure'].append(column)\n",
    "    results['wilcoxon']['Period'].append('t-5 vs t')\n",
    "    results['wilcoxon']['Statistic'].append(stat)\n",
    "    results['wilcoxon']['t-value'].append(t_value)\n",
    "    results['wilcoxon']['p-value'].append(p_value)\n",
    "    \n",
    "    stat, t_value, p_value = perform_wilcoxon_test(df_t, df_t_plus_5, column)\n",
    "    results['wilcoxon']['Measure'].append(column)\n",
    "    results['wilcoxon']['Period'].append('t vs t+5')\n",
    "    results['wilcoxon']['Statistic'].append(stat)\n",
    "    results['wilcoxon']['t-value'].append(t_value)\n",
    "    results['wilcoxon']['p-value'].append(p_value)\n",
    "\n",
    "    #sign Test\n",
    "    stat, p_value = perform_sign_test(df_t_minus_5, df_t, column)\n",
    "    results['sign_test']['Measure'].append(column)\n",
    "    results['sign_test']['Period'].append('t-5 vs t')\n",
    "    results['sign_test']['Statistic'].append(stat)\n",
    "    results['sign_test']['p-value'].append(p_value)\n",
    "    \n",
    "    stat, p_value = perform_sign_test(df_t, df_t_plus_5, column)\n",
    "    results['sign_test']['Measure'].append(column)\n",
    "    results['sign_test']['Period'].append('t vs t+5')\n",
    "    results['sign_test']['Statistic'].append(stat)\n",
    "    results['sign_test']['p-value'].append(p_value)\n",
    "    \n",
    "    #paired T-Test\n",
    "    data_t_minus_5 = df_t_minus_5[column].dropna().values\n",
    "    data_t = df_t[column].dropna().values\n",
    "    data_t_plus_5 = df_t_plus_5[column].dropna().values\n",
    "    min_length_t_minus_5_t = min(len(data_t_minus_5), len(data_t))\n",
    "    min_length_t_t_plus_5 = min(len(data_t), len(data_t_plus_5))\n",
    "    data_t_minus_5 = data_t_minus_5[:min_length_t_minus_5_t]\n",
    "    data_t = data_t[:min_length_t_minus_5_t]\n",
    "    data_t_plus_5 = data_t_plus_5[:min_length_t_t_plus_5]\n",
    "    if len(data_t_minus_5) > 1 and len(data_t) > 1:\n",
    "        stat, p_value = ttest_rel(data_t_minus_5, data_t)\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t-5 vs t')\n",
    "        results['paired_ttest']['Statistic'].append(stat)\n",
    "        results['paired_ttest']['p-value'].append(p_value)\n",
    "    else:\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t-5 vs t')\n",
    "        results['paired_ttest']['Statistic'].append(None)\n",
    "        results['paired_ttest']['p-value'].append(None)\n",
    "    if len(data_t) > 1 and len(data_t_plus_5) > 1:\n",
    "        stat, p_value = ttest_rel(data_t, data_t_plus_5)\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t vs t+5')\n",
    "        results['paired_ttest']['Statistic'].append(stat)\n",
    "        results['paired_ttest']['p-value'].append(p_value)\n",
    "    else:\n",
    "        results['paired_ttest']['Measure'].append(column)\n",
    "        results['paired_ttest']['Period'].append('t vs t+5')\n",
    "        results['paired_ttest']['Statistic'].append(None)\n",
    "        results['paired_ttest']['p-value'].append(None)\n",
    "\n",
    "\n",
    "results_mann_whitney_df = pd.DataFrame(results['mann_whitney'])\n",
    "results_wilcoxon_df = pd.DataFrame(results['wilcoxon'])\n",
    "results_sign_test_df = pd.DataFrame(results['sign_test'])\n",
    "results_paired_ttest_df = pd.DataFrame(results['paired_ttest'])\n",
    "\n",
    "print(results_mann_whitney_df)\n",
    "\n",
    "print(results_wilcoxon_df)\n",
    "\n",
    "print(results_sign_test_df)\n",
    "\n",
    "print(results_paired_ttest_df)\n",
    "\n",
    "output_path = r\"C:\\UU\\THESIS\\AMX\\HYPOTHESIS3\\ownership\\DELETED_IO_NO_significance_test_results_updated.xlsx\"\n",
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    results_mann_whitney_df.to_excel(writer, sheet_name='Mann-Whitney')\n",
    "    results_wilcoxon_df.to_excel(writer, sheet_name='Wilcoxon')\n",
    "    results_sign_test_df.to_excel(writer, sheet_name='Sign Test')\n",
    "    results_paired_ttest_df.to_excel(writer, sheet_name='Paired T-Test')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
